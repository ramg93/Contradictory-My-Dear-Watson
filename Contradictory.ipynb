{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b748a6c6",
   "metadata": {},
   "source": [
    "# Download and Unzip the datasets, if these steps haven't been done yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef51e1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle as k\n",
    "import zipfile as Zip\n",
    "import os \n",
    "\n",
    "directory = 'contradictory-my-dear-watson'\n",
    "if not directory in os.listdir():\n",
    "    !kaggle competitions download -c contradictory-my-dear-watson\n",
    "    with Zip.ZipFile('.'.join([directory, 'zip']), 'r') as zip_ref:\n",
    "        zip_ref.extractall(directory)\n",
    "    \n",
    "if '.'.join([directory, 'zip']) in os.listdir():\n",
    "    os.remove('.'.join([directory, 'zip']))\n",
    "    \n",
    "assert directory in os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d327431c",
   "metadata": {},
   "source": [
    "# Review our datasets and load them into pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f398b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60aa6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6623327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Submission Sample has 5195 rows, 2 columns\n",
      " Test Dataset has 5195 rows, 5 columns\n",
      " Train Dataset has 12120 rows, 6 columns\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(directory)\n",
    "sub_sample, test, train = [pd.read_csv('/'.join([directory, file])) for file in files if os.path.splitext(file)[1] == '.csv']\n",
    "\n",
    "print(f' Submission Sample has {sub_sample.shape[0]} rows, {sub_sample.shape[1]} columns')\n",
    "print(f' Test Dataset has {test.shape[0]} rows, {test.shape[1]} columns')\n",
    "print(f' Train Dataset has {train.shape[0]} rows, {train.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7632b1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission Sample has 5195 unique values for id column\n",
      "Submission Sample has 1 unique values for prediction column\n"
     ]
    }
   ],
   "source": [
    "[print(f'Submission Sample has {len(sub_sample[col].unique())} unique values for {col} column') for col in sub_sample.columns];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff34c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train has 12120 unique values for id column\n",
      "Train has 8209 unique values for premise column\n",
      "Train has 12119 unique values for hypothesis column\n",
      "Train has 15 unique values for lang_abv column\n",
      "Train has 15 unique values for language column\n",
      "Train has 3 unique values for label column\n",
      "\tTrain has 4176 observations for label 0\n",
      "\tTrain has 4064 observations for label 2\n",
      "\tTrain has 3880 observations for label 1\n"
     ]
    }
   ],
   "source": [
    "[print(f'Train has {len(train[col].unique())} unique values for {col} column') for col in train.columns];\n",
    "\n",
    "label_counts = pd.DataFrame(train['label'].value_counts())\n",
    "\n",
    "for i in label_counts.index:\n",
    "    print(f\"\\tTrain has {label_counts.loc[i, 'label']} observations for label {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a13131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test has 5195 unique values for id column\n",
      "Test has 4336 unique values for premise column\n",
      "Test has 5195 unique values for hypothesis column\n",
      "Test has 15 unique values for lang_abv column\n",
      "Test has 15 unique values for language column\n"
     ]
    }
   ],
   "source": [
    "[print(f'Test has {len(test[col].unique())} unique values for {col} column') for col in test.columns];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1796f83",
   "metadata": {},
   "source": [
    "# There are many languages inside Train and Test; therefore, in order to help the model stress less about solving for language, all observations will be translated to English. \n",
    "\n",
    "# Going one-by-one takes a long time (circa, 30 minutes per column, per dataset) so we'll throw this step into a multiprocessing pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "107f2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts_directory = 'scripts'\n",
    "if scripts_directory not in os.listdir():\n",
    "    os.mkdir(scripts_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0813840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/EngTranslator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/EngTranslator.py\n",
    "\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from googletrans import Translator, constants\n",
    "tr = Translator()\n",
    "\n",
    "def toEng(statement = 'text to translate', lan = 'language abbreviation'):\n",
    "    if lan != 'en':\n",
    "        sleep(randint(1, 10))\n",
    "        return tr.translate(statement, dest = 'en').text\n",
    "    else:\n",
    "        return statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f728cc18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train has 12120 unique values for Unnamed: 0 column\n",
      "Train has 12120 unique values for id column\n",
      "Train has 8209 unique values for premise column\n",
      "Train has 12119 unique values for hypothesis column\n",
      "Train has 15 unique values for lang_abv column\n",
      "Train has 15 unique values for language column\n",
      "Train has 3 unique values for label column\n",
      "Train has 8146 unique values for eng_premise column\n",
      "Train has 12119 unique values for eng_hypothesis column\n",
      "\tTrain has 4176 observations for label 0\n",
      "\tTrain has 4064 observations for label 2\n",
      "\tTrain has 3880 observations for label 1\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from scripts.EngTranslator import toEng\n",
    "\n",
    "translation_directory = 'trans_datasets'\n",
    "tr_train_file = 'trans_train.csv'\n",
    "\n",
    "if translation_directory not in os.listdir():\n",
    "    os.mkdir(transaltion_directory)\n",
    "\n",
    "if tr_train_file not in os.listdir(translation_directory):\n",
    "\n",
    "    data2translate = train.loc[:, ['premise', 'hypothesis', 'lang_abv']].values\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        pool = multiprocessing.Pool(processes = 50)\n",
    "        r_premise = pool.starmap(toEng, tqdm([[p,l] for p, _, l in data2translate]))\n",
    "        r_hypothesis = pool.starmap(toEng, tqdm([[h,l] for _, h, l in data2translate]))\n",
    "\n",
    "    train['eng_premise'] = r_premise\n",
    "    train['eng_hypothesis'] = r_hypothesis\n",
    "\n",
    "    train.to_csv('/'.join([translation_directory, tr_train_file]), index = False)\n",
    "\n",
    "else:\n",
    "    train = pd.read_csv('/'.join([translation_directory, tr_train_file]))\n",
    "    [print(f'Train has {len(train[col].unique())} unique values for {col} column') for col in train.columns];\n",
    "\n",
    "    label_counts = pd.DataFrame(train['label'].value_counts())\n",
    "\n",
    "    for i in label_counts.index:\n",
    "        print(f\"\\tTrain has {label_counts.loc[i, 'label']} observations for label {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26bfc5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test has 5195 unique values for Unnamed: 0 column\n",
      "Test has 5195 unique values for id column\n",
      "Test has 4336 unique values for premise column\n",
      "Test has 5195 unique values for hypothesis column\n",
      "Test has 15 unique values for lang_abv column\n",
      "Test has 15 unique values for language column\n",
      "Test has 4329 unique values for eng_premise column\n",
      "Test has 5195 unique values for eng_hypothesis column\n"
     ]
    }
   ],
   "source": [
    "tr_test_file = 'trans_test.csv'\n",
    "\n",
    "if tr_test_file not in os.listdir(translation_directory):\n",
    "    \n",
    "    data2translate = test.loc[:, ['premise', 'hypothesis', 'lang_abv']].values\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        pool = multiprocessing.Pool(processes = 50)\n",
    "        r_premise = pool.starmap(toEng, tqdm([[p,l] for p, _, l in data2translate]))\n",
    "        r_hypothesis = pool.starmap(toEng, tqdm([[h,l] for _, h, l in data2translate]))\n",
    "\n",
    "    test['eng_premise'] = r_premise\n",
    "    test['eng_hypothesis'] = r_hypothesis\n",
    "    \n",
    "    test.to_csv('/'.join([translation_directory, tr_test_file]), index = False)\n",
    "\n",
    "else:\n",
    "    test = pd.read_csv('/'.join([translation_directory, tr_test_file]))\n",
    "    [print(f'Test has {len(test[col].unique())} unique values for {col} column') for col in test.columns];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a1f2c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Train **********\n",
      "premise has 50291 unique words in a 218041 corpus\n",
      "hypothesis has 33810 unique words in a 111447 corpus\n",
      "eng_premise has 25008 unique words in a 225365 corpus\n",
      "eng_hypothesis has 18220 unique words in a 115934 corpus\n",
      "********** Test **********\n",
      "premise has 30007 unique words in a 93621 corpus\n",
      "hypothesis has 18523 unique words in a 47790 corpus\n",
      "eng_premise has 17458 unique words in a 96522 corpus\n",
      "eng_hypothesis has 11254 unique words in a 49687 corpus\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cols = ['premise', 'hypothesis', 'eng_premise', 'eng_hypothesis']\n",
    "\n",
    "print('*'*10, 'Train', '*'*10)\n",
    "for col in cols:\n",
    "    string = ' '.join([train.loc[i, col] for i in train.index])\n",
    "    df = pd.DataFrame(Counter(string.split()).most_common(), columns = ['word', 'count'])\n",
    "    print(f\"{col} has {df.shape[0]} unique words in a {df['count'].sum()} corpus\")\n",
    "\n",
    "print('*'*10, 'Test', '*'*10)\n",
    "for col in cols:\n",
    "    string = ' '.join([test.loc[i, col] for i in test.index])\n",
    "    df = pd.DataFrame(Counter(string.split()).most_common(), columns = ['word', 'count'])\n",
    "    print(f\"{col} has {df.shape[0]} unique words in a {df['count'].sum()} corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc45b20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc303746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765eeb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01914e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
